{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41b7994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting safetensors\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.3.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.9-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.6.2-cp311-cp311-win_amd64.whl.metadata (17 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\deepgpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Downloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Downloading aiohttp-3.12.9-cp311-cp311-win_amd64.whl (449 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.2-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/25.8 MB 13.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.8/25.8 MB 14.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.7/25.8 MB 14.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.5/25.8 MB 14.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.4/25.8 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.6/25.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.4/25.8 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.1/25.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/25.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/25.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/25.8 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 10.9 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pandas-2.3.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 13.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.1 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.1 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, safetensors, regex, pyyaml, pyarrow, propcache, multidict, idna, frozenlist, dill, charset-normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, tokenizers, transformers, datasets\n",
      "\n",
      "   ----------------------------------------  0/28 [pytz]\n",
      "   ----------------------------------------  0/28 [pytz]\n",
      "   ----------------------------------------  0/28 [pytz]\n",
      "   ----------------------------------------  0/28 [pytz]\n",
      "   -- -------------------------------------  2/28 [urllib3]\n",
      "   -- -------------------------------------  2/28 [urllib3]\n",
      "   ---- -----------------------------------  3/28 [tzdata]\n",
      "   ---- -----------------------------------  3/28 [tzdata]\n",
      "   ---- -----------------------------------  3/28 [tzdata]\n",
      "   ---- -----------------------------------  3/28 [tzdata]\n",
      "   ----- ----------------------------------  4/28 [tqdm]\n",
      "   -------- -------------------------------  6/28 [regex]\n",
      "   -------- -------------------------------  6/28 [regex]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   ----------- ----------------------------  8/28 [pyarrow]\n",
      "   -------------- ------------------------- 10/28 [multidict]\n",
      "   --------------- ------------------------ 11/28 [idna]\n",
      "   ------------------ --------------------- 13/28 [dill]\n",
      "   -------------------- ------------------- 14/28 [charset-normalizer]\n",
      "   ---------------------- ----------------- 16/28 [attrs]\n",
      "   --------------------------- ------------ 19/28 [requests]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ---------------------------- ----------- 20/28 [pandas]\n",
      "   ------------------------------ --------- 21/28 [multiprocess]\n",
      "   ------------------------------ --------- 21/28 [multiprocess]\n",
      "   -------------------------------- ------- 23/28 [huggingface-hub]\n",
      "   -------------------------------- ------- 23/28 [huggingface-hub]\n",
      "   -------------------------------- ------- 23/28 [huggingface-hub]\n",
      "   -------------------------------- ------- 23/28 [huggingface-hub]\n",
      "   ---------------------------------- ----- 24/28 [aiohttp]\n",
      "   ---------------------------------- ----- 24/28 [aiohttp]\n",
      "   ---------------------------------- ----- 24/28 [aiohttp]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   ------------------------------------- -- 26/28 [transformers]\n",
      "   -------------------------------------- - 27/28 [datasets]\n",
      "   -------------------------------------- - 27/28 [datasets]\n",
      "   -------------------------------------- - 27/28 [datasets]\n",
      "   -------------------------------------- - 27/28 [datasets]\n",
      "   -------------------------------------- - 27/28 [datasets]\n",
      "   ---------------------------------------- 28/28 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.9 aiosignal-1.3.2 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.2 datasets-3.6.0 dill-0.3.8 frozenlist-1.6.2 huggingface-hub-0.32.4 idna-3.10 multidict-6.4.4 multiprocess-0.70.16 pandas-2.3.0 propcache-0.3.1 pyarrow-20.0.0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4 tzdata-2025.2 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9aa90fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "True\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)  # CUDA version PyTorch was built with\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))  # Your actual GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b167970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\deepgpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import (\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Tokenizer,\n",
    "    TextDataset,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilgpt2\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = f\"../model/fine-tuned-{timestamp}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f54e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # required\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dded5979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcfff4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45dd0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/final_body.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "335bacf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is pretty good God Bless the U S Air Forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attached please find the referenced lists On t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mail The following expense report is ready for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have approved this expense report With regar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sum up my costs and  is cost for this trip and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  This is pretty good God Bless the U S Air Forc...\n",
       "1  Attached please find the referenced lists On t...\n",
       "2  mail The following expense report is ready for...\n",
       "3  I have approved this expense report With regar...\n",
       "4  sum up my costs and  is cost for this trip and..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "data = pd.DataFrame({\"text\": data[0]})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc2589ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=30):\n",
    "        chunks = []\n",
    "        text = text.split(\" \")\n",
    "        for i in range(0, len(text), max_length):\n",
    "            chunks.append(' '.join(text[i:i + max_length]))\n",
    "        return chunks\n",
    "\n",
    "\n",
    "data.text = data.text.apply(lambda text: chunk_text(text))\n",
    "data = data.explode('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69004cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1757bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6635/6635 [00:02<00:00, 2333.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a4b1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4488383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=500,\n",
    "    prediction_loss_only=True,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af76877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa7faafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4977' max='4977' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4977/4977 32:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.918200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.901900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.634400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.653000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4977, training_loss=3.7650310078705798, metrics={'train_runtime': 1929.848, 'train_samples_per_second': 10.314, 'train_steps_per_second': 2.579, 'total_flos': 650138977566720.0, 'train_loss': 3.7650310078705798, 'epoch': 3.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c8a219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2a1699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved at ../model/fine-tuned-20250605_161752\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"✅ Model saved at {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "009ba5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "model_path = \"../model/fine-tuned-20250605_161752\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # required\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install protobuf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "\n",
    "# Step 1: Log in and create repo\n",
    "create_repo(\"smart-compose-model\", private=False)  # public = free inference\n",
    "\n",
    "# Step 2: Load and push your model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"path/to/your/model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"path/to/your/model\")\n",
    "\n",
    "model.push_to_hub(\"your-username/smart-compose-model\")\n",
    "tokenizer.push_to_hub(\"your-username/smart-compose-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 134959 - first version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c4c08a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7597976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete_gpt2(prompt, max_new_tokens=5):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,         # makes it feel \"smart\"\n",
    "        # top_k=30,\n",
    "        # top_p=0.9,\n",
    "        # temperature=0.5,\n",
    "        # repetition_penalty=1.1\n",
    "    )\n",
    "\n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return full_text[len(prompt):].rsplit('.', 1)[0].strip()  # return only new suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1133db6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"week or ' ' '\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocomplete_gpt2(\"Continue this email in a helpful tone and stop after end of sentence or '.': wanna grad dinner next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d96dade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'here is',\n",
    "    'have a',\n",
    "    'please review',\n",
    "    'please call me',\n",
    "    'thanks for',\n",
    "    'let me',\n",
    "    'Let me know',\n",
    "    'Let me know if you',\n",
    "    'this sounds',\n",
    "    'is this call going to',\n",
    "    'can you get',\n",
    "    'is it okay',\n",
    "    'it should',\n",
    "    'call if there\\'s',\n",
    "    'gave her a',\n",
    "    'i will let',\n",
    "    'i will be',\n",
    "    'may i get a copy of all the',\n",
    "    'how is our trade',\n",
    "    'this looks like a',\n",
    "    'i am fine with the changes',\n",
    "    'please be sure this'\n",
    "]\n",
    "import pandas as pd\n",
    "output = list(map(autocomplete_gpt2, texts))\n",
    "output_df = pd.DataFrame({'input': texts, 'output': output})\n",
    "# output_df.head(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a4f9009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here is</td>\n",
       "      <td>the latest issue of our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have a</td>\n",
       "      <td>chance to talk to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please review</td>\n",
       "      <td>and act upon this information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please call me</td>\n",
       "      <td>at if you have any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks for</td>\n",
       "      <td>your help in this matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>let me</td>\n",
       "      <td>know if you have any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Let me know</td>\n",
       "      <td>if you have any questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Let me know if you</td>\n",
       "      <td>have any questions Thanks for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>this sounds</td>\n",
       "      <td>like a good idea to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is this call going to</td>\n",
       "      <td>be a good one for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>can you get</td>\n",
       "      <td>a copy of the spreadsheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is it okay</td>\n",
       "      <td>to go to the doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it should</td>\n",
       "      <td>be done in the morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>call if there's</td>\n",
       "      <td>any need for a new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gave her a</td>\n",
       "      <td>nice day and I will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i will let</td>\n",
       "      <td>you know when I get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i will be</td>\n",
       "      <td>in the office until the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>may i get a copy of all the</td>\n",
       "      <td>information from the database and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>how is our trade</td>\n",
       "      <td>strategy for the next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>this looks like a</td>\n",
       "      <td>good idea to me I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>i am fine with the changes</td>\n",
       "      <td>to the rules I am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>please be sure this</td>\n",
       "      <td>is the correct address for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          input                             output\n",
       "0                       here is            the latest issue of our\n",
       "1                        have a              chance to talk to you\n",
       "2                 please review      and act upon this information\n",
       "3                please call me                 at if you have any\n",
       "4                    thanks for           your help in this matter\n",
       "5                        let me               know if you have any\n",
       "6                   Let me know          if you have any questions\n",
       "7            Let me know if you      have any questions Thanks for\n",
       "8                   this sounds                like a good idea to\n",
       "9         is this call going to                  be a good one for\n",
       "10                  can you get          a copy of the spreadsheet\n",
       "11                   is it okay                to go to the doctor\n",
       "12                    it should             be done in the morning\n",
       "13              call if there's                 any need for a new\n",
       "14                   gave her a                nice day and I will\n",
       "15                   i will let                you know when I get\n",
       "16                    i will be            in the office until the\n",
       "17  may i get a copy of all the  information from the database and\n",
       "18             how is our trade         strategy for the next week\n",
       "19            this looks like a                  good idea to me I\n",
       "20   i am fine with the changes                  to the rules I am\n",
       "21          please be sure this         is the correct address for"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85125a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
